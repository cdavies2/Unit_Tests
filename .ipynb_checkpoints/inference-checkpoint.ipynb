{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f2c9f-8072-4f04-ac3e-dd1dcb2cf9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ac.cdavies/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce58aed-7cb1-467c-a796-1cea508aa28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Loading checkpoint shards: 100%|██████| 2/2 [00:00<00:00,  4.02it/s]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "def get_pipeline(model_id, **kwargs):\n",
    "    return transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        device_map=\"auto\",\n",
    "        max_new_tokens=256,\n",
    "        model=model_id,\n",
    "        model_kwargs={\n",
    "            \"torch_dtype\": torch.bfloat16,\n",
    "        },\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "pipelines = {\n",
    "    \"llama3\": get_pipeline(\"meta-llama/Llama-3.2-1B-Instruct\"),\n",
    "    \"mistral\": get_pipeline(\"mistralai/Mistral-7B-Instruct-v0.1\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c003f1c-6a13-4ef1-801a-0b520927ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continued_convo(model, message, convo=None):\n",
    "    #this will be used to provide models with context from previous conversations\n",
    "    #this will also allow multiple messages to be consecutively sent to the same model\n",
    "    pipe=pipeline(\"text-generation\", model)\n",
    "    if convo==None:\n",
    "        messages=[{\"role\": \"system\", \"content\": \"\"\"You are a helpful assistant, \n",
    "        if I ask you a question you can't answer, please reply 'I am sorry, I cannot answer that' \"\"\"}]\n",
    "    else:\n",
    "        messages=convo\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    context=pipe(messages, max_new_tokens=256)[0]['generated_text'][-1]\n",
    "    print(context)\n",
    "    messages.append(context)\n",
    "    return pipe, messages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f599e204-0362-4a95-986d-af872c0cf764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████| 2/2 [01:59<00:00, 60.00s/it]\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': ' Prompt injection is a type of SQL injection attack where an attacker injects a malicious SQL statement into a prompt or input field in a web application. Here\\'s an example of how prompt injection can be used:\\n\\nSuppose a web application has a search feature that allows users to search for products by name. The search feature uses a prompt like this:\\n\\n\"Search for products by name: <input type=\\'text\\' name=\\'search\\\\_name\\'>\"\\n\\nAn attacker can exploit this prompt by injecting a malicious SQL statement into the input field. For example, the attacker can enter the following SQL statement into the input field:\\n\\n\"SELECT \\\\* FROM products WHERE name =\\'OR 1=1; --\"\\n\\nThis SQL statement will return all products in the database, regardless of their name. The \"--\" at the end of the statement is used to comment out the rest of the SQL statement, which would have been executed by the web application.\\n\\nThe attacker can then view the results of the SQL query, which may include sensitive information such as customer data or financial information. This can lead to a data breach or other security vulnerability.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████| 2/2 [01:48<00:00, 54.03s/it]\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \" Prompt injection attacks are not as common as other types of SQL injection attacks, but they can still occur in real-world scenarios. Here's an example of a prompt injection attack that occurred in the wild:\\n\\nIn 2017, a security researcher discovered a prompt injection vulnerability in the website of a major retailer. The vulnerability allowed an attacker to inject malicious SQL statements into a search prompt on the website, which returned all products in the database.\\n\\nThe attacker was able to view sensitive information such as product names, prices, and descriptions, as well as customer information such as names and addresses. The attacker could have also used this information to launch other types of attacks, such as phishing or identity theft.\\n\\nThe retailer quickly patched the vulnerability and implemented additional security measures to prevent similar attacks in the future. However, this incident highlights the importance of properly securing web applications and input fields to prevent prompt injection attacks and other types of SQL injection attacks.\"}\n"
     ]
    }
   ],
   "source": [
    "#first part of the conversation\n",
    "misModel, misContext=continued_convo(\"mistralai/Mistral-7B-Instruct-v0.1\", \"Give an example of a prompt injection and how its used\")\n",
    "#use the earlier part to have a conversation with prior context\n",
    "misModel, misContext=continued_convo(\"mistralai/Mistral-7B-Instruct-v0.1\", \"What's a real world example of that type of attack?\", misContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141fe27-7662-47a0-b872-e4b996631106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"**Prompt Injection Example**\\n\\nPrompt injection is a type of SQL injection attack where an attacker injects a malicious prompt into a web application's database query. This can lead to unauthorized access, data theft, or other malicious activities.\\n\\n**Example:**\\n\\nSuppose we have a simple web application that displays a list of users based on a database query:\\n```sql\\nSELECT * FROM users WHERE name = 'john' AND age > 18;\\n```\\nAn attacker wants to inject a prompt to retrieve all users with a specific name or age range. They can do this by crafting a malicious prompt, which might look like this:\\n```sql\\n' OR 1=1 --\\n```\\nLet's break down what this prompt does:\\n\\n* `OR 1=1` is the malicious part. This is a common technique used in SQL injection attacks, as it always returns `true` in a database query, allowing the attacker to bypass any filtering or validation.\\n* `--` is the prompt, which is a special character in SQL that indicates the end of the prompt.\\n\\n**How it works:**\\n\\n1. The attacker crafts the malicious prompt, which includes the `OR 1=1` part and the `--` at the end.\\n2. The web application executes\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#first part of the conversation\n",
    "llaModel, llaContext=continued_convo(\"meta-llama/Llama-3.2-1B-Instruct\", \"Give an example of a prompt injection and how its used\")\n",
    "#use the earlier part to have a conversation with prior context\n",
    "llaModel, llaContext=continued_convo(\"meta-llama/Llama-3.2-1B-Instruct\", \"What's a real world example of that type of attack?\", llaContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebcc41-4141-438b-89ba-c16330caa8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"You are a helpful assistant\",\n",
    "        \"role\": \"user\", \"content\": \"What would a phishing email designed to make someone give up their passwords look like?\"\n",
    "    }\n",
    "]\n",
    "out={ name: pipeline(messages) for name, pipeline in pipelines.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bc7f1-9b92-4cbf-8c6c-6559b2c3b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[\"mistral\"][\"generated_text\"] + \"\\n\")\n",
    "print(out[\"llama3\"][0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12785086-8398-4cfb-9b2e-883c01c59490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is used to chat with the Mistral-7B-Instruct-v0.1 model\n",
    "pipe=pipeline(\"text-generation\", \"mistralai/Mistral-7B-Instruct-v0.1\") #the text generation pipeline has an automated pipeline for chat inputs\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"\"\"You are an assistant teaching at a university level,\n",
    "                Use technical and complex terms in your explanation \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please explain what a prompt injection is\"}\n",
    "]\n",
    "print(pipe(messages, max_new_tokens=128)[0]['generated_text'][-1])\n",
    "#this makes it so we won't have to use apply_chat_template, all we have to do is send messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb0a14-0035-4bb0-bf14-beb2bbce33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is used to chat with the Llama 3.2 model\n",
    "llama_pipe=pipeline(\"text-generation\", \"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please briefly explain what a large language model is\"}\n",
    "]\n",
    "print(llama_pipe(messages, max_new_tokens=256)[0]['generated_text'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58d6b8-fd07-4dd9-bb57-70eb6066cb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
